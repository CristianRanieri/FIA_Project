# -*- coding: utf-8 -*-
"""CarPricePredictorRModel.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12zQnYbOctzxzggA4Jgtnpe_wlPr82fG7
"""

import pandas as pd

dataset = pd.read_csv("automobili.csv")

# Utilizziamo la funzione isna() per trovare i valori nulli, e la funzione sum() per contarli
nan_mask = dataset.isna()
nan_count = nan_mask.sum()

print("Tabella dei valori null:")
print(nan_count)
print()

"""Non ci sono valori null, ma il il 30% dei dati per Levy è uguale a "-", quindi non conosciuto, dato l'elevato numero ho deciso di eliminarla come colonna."""

if "Levy" in dataset.columns:
    # Elimina la colonna "Levy"
    dataset = dataset.drop("Levy", axis=1)

"""Elimino la colonna "Engine Volume" e "" visto che è un dato che e facilmente ottenibile in fase di utilizzo del modello."""

if "Engine volume" in dataset.columns:
    # Elimina la colonna "Levy"
    dataset = dataset.drop("Engine volume", axis=1)

"""Elimino la colonna ID visto che non ha nessun valore predittivo"""

if "ID" in dataset.columns:
    # Elimina la colonna "Levy"
    dataset = dataset.drop("ID", axis=1)

"""Il campo Doors ha un errore bisogna sostituire "04-May" con "4" "02-Mar" con "2" e ">5" con "5"
"""

# Sostituisci i valori nel campo 'Doors'
dataset['Doors'] = dataset['Doors'].replace({'04-May': '4', '02-Mar': '2', '>5': '5'})

# Converti il campo 'Doors' in numeri
dataset['Doors'] = dataset['Doors'].astype(int)

# Verifica le modifiche
print("Sostituizione dei valro di dors, nuovi valori:")
print(dataset['Doors'].unique())

# Elimina il suffisso " km" dalla parte destra della colonna Mileage
dataset['Mileage'] = dataset['Mileage'].str.rstrip(' km')

"""Verifico di aver eliminato tutte le occorrenze di " km" in Mileage."""

# Specifica il suffisso da cercare (ad esempio, " km")
suffisso_da_cercare = " km"

# Conta il numero di occorrenze del suffisso nella colonna Mileage
numero_occasioni = (dataset['Mileage'].str.contains(suffisso_da_cercare)).sum()

# Stampa il risultato
print()
print("Rimozione della desinenza ' km' nella variabile Mileage")
print(f"Numero di occorrenze di '{suffisso_da_cercare}' nella colonna Mileage: {numero_occasioni}")

#converto il dato Milages da stringa a numero
dataset['Mileage'] = pd.to_numeric(dataset['Mileage'], errors='coerce')

"""L'attributo dataset "Manufacturer" ha diversi valori unici i quali non rappresentano un informazione utile per effettuare una predizione quindi creo una nuova categorica Other nelle quali le accorpo."""

dataset = dataset[(dataset['Price'] >= 4000) & (dataset['Price'] <= 700000)]

# Calcola il conteggio delle occorrenze di ciascun valore nella colonna 'Manufacturer'
manufacturer_counts = dataset['Manufacturer'].value_counts()

# Identifica i valori che si verificano meno di 5 volte
values_to_replace = manufacturer_counts[manufacturer_counts <= 10].index

# Sostituisci i valori con 'Other'
dataset['Manufacturer'] = dataset['Manufacturer'].replace(values_to_replace, 'Other')

dataset['Manufacturer'].value_counts()

"""Fare prima "One Hot Encoding" e il "Data Scaling"?
Dipende dalla situazione bisogna provare entrambi.
Provo prima a fare "Data Scaling" e poi "One Hot Encoding" quando avro bisogno di utilizzare un algoritmo che si basa solo su valori numerici.
Utilizzo Z-Score Normalization visto che per algoritmi come Regressione lineare risulta generalmente mogliore, visto che porta piu velocemente a convergenza.
"""

from sklearn.preprocessing import StandardScaler

# Seleziona solo le colonne numeriche su cui applicare lo Z-score
colonnes_numeriche = dataset.select_dtypes(include=['int64', 'float64']).columns

# Inizializza lo StandardScaler
scaler = StandardScaler()

# Applica lo Z-score alle colonne numeriche
dataset[colonnes_numeriche] = scaler.fit_transform(dataset[colonnes_numeriche])

"""Calcolo la correlazione di pearsonr per determinare la correlazione delle variabili numeriche"""

from scipy.stats import pearsonr, spearmanr

# Seleziona solo le colonne numeriche
colonnes_numeriche = ['Mileage', 'Prod. year', 'Cylinders', 'Airbags']

# Calcola il coefficiente di correlazione di Pearson solo per le coppie che contengono "Price"
for colonna in colonnes_numeriche:
    correlation_spearman, p_value_spearman = pearsonr(dataset['Price'], dataset[colonna])
    print(f"Coefficiente di correlazione di Spearman tra Price e {colonna}: {correlation_spearman}\nP-value: {p_value_spearman}\n")

"""Ecco l'interpretazione dei risultati ottenuti:

Price e Mileage:
Coefficiente di Correlazione di Spearman: -0.20453684714429626
P-value: 8.898376748162581e-181

Interpretazione: Il coefficiente di correlazione di Spearman tra "Price" e "Mileage" è -0.2045, indicando una correlazione inversa. Questo significa che, in generale, all'aumentare del prezzo, la quantità di chilometri percorsi tende a diminuire. Il p-value è molto vicino a zero, indicando che questa correlazione è statisticamente significativa.

Price e Prod. year:
Coefficiente di Correlazione di Spearman: 0.2931
P-value: 0.0

Interpretazione: Il coefficiente di correlazione di Spearman tra "Price" e "Prod. year" è 0.2931, indicando una correlazione positiva. Questo suggerisce che, in generale, all'aumentare dell'anno di produzione, il prezzo tende a aumentare. Il p-value è molto vicino a zero, indicando che questa correlazione è statisticamente significativa.

Price e Cylinders:
Coefficiente di Correlazione di Spearman: -0.0310
P-value: 1.6974825617411518e-05

Interpretazione: Il coefficiente di correlazione di Spearman tra "Price" e "Cylinders" è -0.0310, indicando una correlazione inversa, anche se molto debole. Il p-value è basso, indicando che questa correlazione è statisticamente significativa, ma la forza della correlazione è debole.

Price e Airbags:
Coefficiente di Correlazione di Spearman: -0.0574
P-value: 1.7126214075366264e-15

Interpretazione: Il coefficiente di correlazione di Spearman tra "Price" e "Airbags" è -0.0574, indicando una correlazione inversa, ma anch'essa debole. Il p-value è molto basso, indicando che questa correlazione è statisticamente significativa.

In sintesi, questi risultati suggeriscono che le variabili "Mileage", "Prod. year", "Cylinders" e "Airbags" sono correlate al prezzo dell'auto, con differenti gradi di forza di correlazione. La direzione (positiva o negativa) indica come le variabili tendono a variare insieme. Il p-value basso suggerisce che queste correlazioni non sono dovute al caso.

Come criterio per determinare la correlazione tra la variabile Price che è nimerica e le variabili categoriche ho deciso di analizzare la varianza applicando la technica ANOVA.
"""

from scipy.stats import f_oneway

# Trova le categorie uniche di 'Manufacturer'
manufacturer_categories = dataset['Manufacturer'].unique()

# Crea una lista di serie contenenti i prezzi per ogni categoria
price_by_category = [dataset[dataset['Manufacturer'] == category]['Price'] for category in manufacturer_categories]

# Esegui l'ANOVA utilizzando le serie dei prezzi
f_statistic, p_value = f_oneway(*price_by_category)

# Stampa dei risultati
print()
print("Risultato di ANOVa per la variabile Manufacturer:")
print(f"F-statistic: {f_statistic}")
print(f"P-value: {p_value}")

"""P-value inferoiore a 0.05 cio significa che probabilmente la correlazione tra la categoria ed il prezzo e molto alta quindi questo parametro ha un alto valore predittivo."""

# Trova le categorie uniche di 'Model'
manufacturer_categories = dataset['Model'].unique()

# Crea una lista di serie contenenti i prezzi per ogni categoria
price_by_category = [dataset[dataset['Model'] == category]['Price'] for category in manufacturer_categories]

# Esegui l'ANOVA utilizzando le serie dei prezzi
f_statistic, p_value = f_oneway(*price_by_category)

# Stampa dei risultati
print()
print("Risultato di ANOVa per la variabile Model:")
print(f"F-statistic: {f_statistic}")
print(f"P-value: {p_value}")

"""Dato l'elevato numero di dati unici, potenza predittiva nulla(su 19000 record 17077 categorie diverse).

"""

# Trova le categorie uniche di 'Category'
manufacturer_categories = dataset['Category'].unique()

# Crea una lista di serie contenenti i prezzi per ogni categoria
price_by_category = [dataset[dataset['Category'] == category]['Price'] for category in manufacturer_categories]

# Esegui l'ANOVA utilizzando le serie dei prezzi
f_statistic, p_value = f_oneway(*price_by_category)

# Stampa dei risultati
print()
print("Risultato di ANOVa per la variabile Category:")
print(f"F-statistic: {f_statistic}")
print(f"P-value: {p_value}")

"""P-value inferoiore a 0.05 cio significa che probabilmente la correlazione tra la categoria ed il prezzo e molto alta quindi questo parametro ha un alto valore predittivo."""

# Trova le categorie uniche di 'Leather interior'
manufacturer_categories = dataset['Leather interior'].unique()

# Crea una lista di serie contenenti i prezzi per ogni categoria
price_by_category = [dataset[dataset['Leather interior'] == category]['Price'] for category in manufacturer_categories]

# Esegui l'ANOVA utilizzando le serie dei prezzi
f_statistic, p_value = f_oneway(*price_by_category)

# Stampa dei risultati
print()
print("Risultato di ANOVa per la variabile Leather interior:")
print(f"F-statistic: {f_statistic}")
print(f"P-value: {p_value}")

"""P-value inferoiore a 0.05 cio significa che probabilmente la correlazione tra la categoria ed il prezzo e molto alta quindi questo parametro ha un alto valore predittivo."""

# Trova le categorie uniche di 'Fuel type'
manufacturer_categories = dataset['Fuel type'].unique()

# Crea una lista di serie contenenti i prezzi per ogni categoria
price_by_category = [dataset[dataset['Fuel type'] == category]['Price'] for category in manufacturer_categories]

# Esegui l'ANOVA utilizzando le serie dei prezzi
f_statistic, p_value = f_oneway(*price_by_category)

# Stampa dei risultati
print()
print("Risultato di ANOVa per la variabile Fuel type:")
print(f"F-statistic: {f_statistic}")
print(f"P-value: {p_value}")

"""P-value inferoiore a 0.05 cio significa che probabilmente la correlazione tra la categoria ed il prezzo e molto alta quindi questo parametro ha un alto valore predittivo."""

# Trova le categorie uniche di 'Gear box type'
manufacturer_categories = dataset['Gear box type'].unique()

# Crea una lista di serie contenenti i prezzi per ogni categoria
price_by_category = [dataset[dataset['Gear box type'] == category]['Price'] for category in manufacturer_categories]

# Esegui l'ANOVA utilizzando le serie dei prezzi
f_statistic, p_value = f_oneway(*price_by_category)

# Stampa dei risultati
print()
print("Risultato di ANOVa per la variabile Gear box type:")
print(f"F-statistic: {f_statistic}")
print(f"P-value: {p_value}")

"""P-value inferoiore a 0.05 cio significa che probabilmente la correlazione tra la categoria ed il prezzo e molto alta quindi questo parametro ha un alto valore predittivo."""

# Trova le categorie uniche di 'Drive wheels'
manufacturer_categories = dataset['Drive wheels'].unique()

# Crea una lista di serie contenenti i prezzi per ogni categoria
price_by_category = [dataset[dataset['Drive wheels'] == category]['Price'] for category in manufacturer_categories]

# Esegui l'ANOVA utilizzando le serie dei prezzi
f_statistic, p_value = f_oneway(*price_by_category)

# Stampa dei risultati
print()
print("Risultato di ANOVa per la variabile Drive wheels:")
print(f"F-statistic: {f_statistic}")
print(f"P-value: {p_value}")

"""P-value inferoiore a 0.05 cio significa che probabilmente la correlazione tra la categoria ed il prezzo e molto alta quindi questo parametro ha un alto valore predittivo."""

# Trova le categorie uniche di 'Doors'
manufacturer_categories = dataset['Doors'].unique()

# Crea una lista di serie contenenti i prezzi per ogni categoria
price_by_category = [dataset[dataset['Doors'] == category]['Price'] for category in manufacturer_categories]

# Esegui l'ANOVA utilizzando le serie dei prezzi
f_statistic, p_value = f_oneway(*price_by_category)

# Stampa dei risultati
print()
print("Risultato di ANOVa per la variabile Doors:")
print(f"F-statistic: {f_statistic}")
print(f"P-value: {p_value}")

"""P-value inferoiore a 0.05 cio significa che probabilmente la correlazione tra la categoria ed il prezzo e molto alta quindi questo parametro ha un alto valore predittivo."""

# Trova le categorie uniche di 'Wheel'
manufacturer_categories = dataset['Wheel'].unique()

# Crea una lista di serie contenenti i prezzi per ogni categoria
price_by_category = [dataset[dataset['Wheel'] == category]['Price'] for category in manufacturer_categories]

# Esegui l'ANOVA utilizzando le serie dei prezzi
f_statistic, p_value = f_oneway(*price_by_category)

# Stampa dei risultati
print()
print("Risultato di ANOVa per la variabile Wheel:")
print(f"F-statistic: {f_statistic}")
print(f"P-value: {p_value}")

"""P-value inferoiore a 0.05 cio significa che probabilmente la correlazione tra la categoria ed il prezzo e molto alta quindi questo parametro ha un alto valore predittivo."""

# Trova le categorie uniche di 'Color'
manufacturer_categories = dataset['Color'].unique()

# Crea una lista di serie contenenti i prezzi per ogni categoria
price_by_category = [dataset[dataset['Color'] == category]['Price'] for category in manufacturer_categories]

# Esegui l'ANOVA utilizzando le serie dei prezzi
f_statistic, p_value = f_oneway(*price_by_category)

# Stampa dei risultati
print()
print("Risultato di ANOVa per la variabile Color:")
print(f"F-statistic: {f_statistic}")
print(f"P-value: {p_value}")

"""P-value inferoiore a 0.05 cio significa che probabilmente la correlazione tra la categoria ed il prezzo e molto alta quindi questo parametro ha un alto valore predittivo.

Quindi dall'analisi della varianza delle variabili categoriche si è determinato che per quanto riguarda la variabile "Model" visto che a livello di significato nel dominio del problema è altamente influente ma allo stesso tempo il test statistico ha determinato che risulta essere poco influente, per determinarne l'utilita reale verranno creati due modelli e si testeranno le differenze a livello delle metriche predittive.
"""

# Colonnes da eliminare
colonne_da_elimare = ["Model"]

# Elimina le colonne specificate
dataset = dataset.drop(colonne_da_elimare, axis=1)

"""Prima di poter applicare un algoritmo di Decision Three o di Regressione lineare bisogna trasformare le variabili categoriche in variabili numeriche."""

import pandas as pd
from sklearn.preprocessing import LabelEncoder

# Seleziona colonne categoriche
colonne_categoriche = dataset.select_dtypes(include=['object']).columns

# Applica Label Encoding a ciascuna colonna categorica
label_encoder = LabelEncoder()
for colonna in colonne_categoriche:
    dataset[colonna] = label_encoder.fit_transform(dataset[colonna])

# Stampa il DataFrame dopo Label Encoding
print("\nDataFrame dopo Label Encoding:")
print(dataset)

import numpy as np
from sklearn.model_selection import cross_validate
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import make_scorer, r2_score, mean_absolute_error, mean_squared_error, accuracy_score, precision_score, mean_absolute_percentage_error

# Seleziona le feature e la variabile target
features = [colonna for colonna in dataset.columns if colonna != 'Price']
X = dataset[features]
y = dataset['Price']

# Definisci le metriche
metriche = {
    'R-squared': make_scorer(r2_score),
    'MAPE': make_scorer(mean_absolute_percentage_error),
    'MSE': make_scorer(mean_squared_error),
    'RMSE': make_scorer(lambda y_true, y_pred: np.sqrt(mean_squared_error(y_true, y_pred))),
}

# Modello di albero decisionale per la regressione
modello_albero_regressione = DecisionTreeRegressor()

# Esegui la K-Fold Cross-Validation con diverse metriche
risultati = cross_validate(modello_albero_regressione, X, y, cv=10, scoring=metriche)

# Stampa i risultati
print()
print("Modello ad albero decisionale metriche:")
for metrica, valori in risultati.items():
    print(f"{metrica} medio: {np.mean(valori)}")

"""Valori riportati nel loro range di origine:

Test MSE medio riscalato = 33482.34

Test RMSE medio riscalato = 183.026

Il Mean Absolute Percentage Error (MAPE) rappresenta l'errore percentuale medio delle previsioni rispetto ai valori reali. Un MAPE del 1.8378% indica una precisione accettabile delle previsioni, ma potrebbe essere utile esaminare i casi in cui il MAPE è più elevato per capire meglio le situazioni in cui il modello ha difficoltà.

Esempio: Un MAPE del 1.8378% significa che, in media, le previsioni del modello si discostano dal valore reale del 1.8378%. Ad esempio, se il modello prevede una vendita di 100 unità, il valore reale potrebbe variare in media del 1.8378%, quindi potrebbe essere previsto un numero compreso tra 98.1622 e 101.8378 unità.

Il valore medio del coefficiente di determinazione (R-squared) durante la validazione incrociata è 0.419. Questo valore indica quanto bene il modello è in grado di spiegare la variazione nei dati di output. Un R-squared più vicino a 1.0 suggerisce una buona adattabilità del modello ai dati, mentre valori più bassi indicano una minore capacità del modello di spiegare la variazione. Nel tuo caso, un R-squared medio del 0.419 suggerisce che il modello ha una moderata capacità di spiegare la variazione nei dati.

Esempio: L'MSE di 0.6269 rappresenta l'errore quadratico medio. Se stiamo predendo i risultati delle misurazioni di una variabile, l'errore quadratico medio è la media dei quadrati delle differenze tra le previsioni del modello e i valori reali. Ad esempio, se stiamo predendo la temperatura, potremmo avere un errore quadratico di 0.6269, il che suggerisce che, in media, gli errori di previsione sono moderati.
Test RMSE medio: 0.7814

Esempio: L'RMSE di 0.7814 è la radice quadrata dell'MSE. Se stiamo ancora considerando la previsione della temperatura, l'RMSE rappresenterebbe la deviazione standard degli errori. Un RMSE di 0.7814 indica che, in media, gli errori sono distribuiti intorno a 0.7814 gradi Celsius.
"""

import numpy as np
from sklearn.model_selection import cross_validate
from sklearn.linear_model import LinearRegression
from sklearn.metrics import make_scorer, r2_score, mean_absolute_error, mean_squared_error

# Modello di regressione lineare
modello_lineare_regressione = LinearRegression()

# Esegui la K-Fold Cross-Validation con diverse metriche
risultati = cross_validate(modello_lineare_regressione, X, y, cv=10, scoring=metriche)

# Stampa i risultati
print()
print("Modello di regressione lineare metriche:")
for metrica, valori in risultati.items():
    print(f"{metrica} medio: {np.mean(valori)}")

valore_massimo = dataset['Price'].max()
valore_minimo = dataset['Price'].min()

print(f"Valore massimo: {valore_massimo}")
print(f"Valore minimo: {valore_minimo}")

"""tutte le metriche sono mogliorate risulta generalmente mogliore.

**R-squared medio:**
Il R-squared medio è negativo, il che indica che il modello di regressione lineare non riesce a catturare la variazione nei dati di output. Potrebbe indicare che il modello non è adatto per il tipo di relazione tra le variabili indipendenti e dipendenti.

**Errore Assoluto Medio (MAE) medio:**
Il MAE medio è di circa 0.072, il che potrebbe essere considerato relativamente basso. Indica che, in media, le predizioni del modello si discostano di circa 0.051 unità dalla variabile target reale.

**Errore Quadrato Medio (MSE) medio: **
Il MSE medio è di circa 1.000, il che rappresenta la media degli errori quadrati. Tuttavia, questa metrica può essere influenzata da valori anomali.

**Radice dell'Errore Quadrato Medio (RMSE) medio:**
Il RMSE medio è di circa 0.408, che rappresenta la radice quadrata del MSE. Indica la deviazione standard degli errori del modello. Come il MAE, è una misura della precisione delle predizioni.

Il R-squared (coefficiente di determinazione) fornisce una misura della bontà di adattamento del modello ai dati. Il suo valore può variare da -∞ a 1, dove 1 indica un modello perfetto che spiega tutta la variazione nei dati. Tuttavia, è possibile ottenere valori negativi, il che indica che il modello è peggiore rispetto a un modello medio che prenderebbe semplicemente la media della variabile target.

Un R-squared negativo può verificarsi quando il modello lineare non è in grado di catturare la variazione nei dati, e l'output previsto è peggio di una semplice stima della media. In altre parole, il modello non fornisce alcun beneficio rispetto a una stima costante. Questo può accadere quando la relazione tra le variabili indipendenti e dipendenti non è approssimabile da una funzione lineare.

In sostanza, un R-squared medio negativo indica che il modello di regressione lineare attuale non è adatto per la previsione della variabile target nel tuo dataset. Potrebbe essere necessario esplorare modelli più complessi o considerare altre trasformazioni delle variabili per migliorare le prestazioni del modello.

ANCHE ELIMINANDO MODEL I PARAMETRI NON SUBISCONO CAMBIAMENTI

Normalità dei residui:

Puoi controllare la normalità dei residui tracciando un istogramma dei residui o un grafico quantile-quantile (Q-Q plot). Se i residui seguono approssimativamente una distribuzione normale, allora la normalità è soddisfatta.
Omoschedasticità:

Per valutare l'omoschedasticità, traccia un grafico dei residui rispetto alle previsioni del modello. Se i residui mostrano una dispersione costante e uniforme lungo tutti i valori previsti, allora l'omoschedasticità è presente. Altrimenti, potrebbe esserci eteroschedasticità.
Indipendenza degli errori:

Puoi controllare l'indipendenza degli errori tracciando un grafico dei residui nel tempo (se i dati sono temporali) o in base all'ordine di osservazione. Se non c'è nessun modello evidente o tendenza nei residui, allora l'indipendenza degli errori è probabile.
"""

import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

# Supponiamo che 'X' sia la tua variabile indipendente e 'y' sia la tua variabile dipendente
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Crea e addestra il modello di regressione lineare
modello_lineare = LinearRegression()
modello_lineare.fit(X_train, y_train)

# Effettua le previsioni
previsioni = modello_lineare.predict(X_test)

# Calcola i residui
residui = y_test - previsioni

plt.figure(figsize=(8, 6))
plt.scatter(previsioni, residui)
plt.title('Grafico dei Residui rispetto alle Previsioni')
plt.xlabel('Previsioni')
plt.ylabel('Residui')
plt.grid(True)  # Aggiungi griglia per una migliore visualizzazione
plt.show()

"""non c'è Omoschedasticità, i residui del test seguno una semiretta"""

import statsmodels.api as sm
from statsmodels.stats.diagnostic import het_breuschpagan

# Aggiungi una colonna costante a X_osservazioni
X_osservazioni = sm.add_constant(X_test)

# Calcola i residui del modello
residui = y_test - previsioni

# Esegui il test di Breusch-Pagan
_, p_value, _, _ = het_breuschpagan(residui, X_osservazioni)
print(f"P-value del test di Breusch-Pagan: {p_value}")

"""Conferma di non omoschedaticita il valore è minore di 0.05."""

import statsmodels.api as sm
import matplotlib.pyplot as plt

# Crea il Q-Q plot
sm.qqplot(residui, line='s')
plt.show()

"""Il Q-Q plot confronta i quantili osservati dei residui con i quantili teorici di una distribuzione normale. Visto che i punti nel Q-Q plot si allineano approssimativamente con una linea retta rossa, significa che i residui seguono una distribuzione normale."""

import statsmodels.api as sm

# Supponiamo che 'residui' siano gli errori residui del tuo modello
durbin_watson_statistic = sm.stats.stattools.durbin_watson(residui)

# Stampa il risultato del test di Durbin-Watson
print(f"Statistiche del test di Durbin-Watson: {durbin_watson_statistic}")

# Interpretazione del risultato
if durbin_watson_statistic < 1.5:
    print("Autocorrelazione positiva nei residui.")
elif durbin_watson_statistic > 2.5:
    print("Autocorrelazione negativa nei residui.")
else:
    print("Gli errori residui sono indipendenti.")

"""Il valore del testi è vicino a 2 quindi i residui sono indipendenti"""