# -*- coding: utf-8 -*-
"""CarPricePredictor.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1r7F5Gv2UPSzdZ3s0eTaJCqgWfzZdt0Lk
"""

import pandas as pd

dataset = pd.read_csv("automobili.csv")

# Utilizziamo la funzione isna() per trovare i valori nulli, e la funzione sum() per contarli
nan_mask = dataset.isna()
nan_count = nan_mask.sum()

print("Tabella dei valori null:")
print(nan_count)
print()

"""Non ci sono valori null, ma il il 30% dei dati per Levy è uguale a "-", quindi non conosciuto, dato l'elevato numero ho deciso di eliminarla come colonna."""

if "Levy" in dataset.columns:
    # Elimina la colonna "Levy"
    dataset = dataset.drop("Levy", axis=1)

"""Elimino la colonna "Engine Volume" e "" visto che è un dato che e facilmente ottenibile in fase di utilizzo del modello."""

if "Engine volume" in dataset.columns:
    # Elimina la colonna "Levy"
    dataset = dataset.drop("Engine volume", axis=1)

"""Elimino la colonna ID visto che non ha nessun valore predittivo"""

if "ID" in dataset.columns:
    # Elimina la colonna "Levy"
    dataset = dataset.drop("ID", axis=1)

# Sostituisci i valori nel campo 'Doors'
dataset['Doors'] = dataset['Doors'].replace({'04-May': '4', '02-Mar': '2', '>5': '5'})

# Converti il campo 'Doors' in numeri
dataset['Doors'] = dataset['Doors'].astype(int)

# Verifica le modifiche
print("Sostituizione dei valro di dors, nuovi valori:")
print(dataset['Doors'].unique())

"""Il campo Doors ha un errore bisogna sostituire "04-May" con "4" "02-Mar" con "2" e ">5" con "5"
"""

# Elimina il suffisso " km" dalla parte destra della colonna Mileage
dataset['Mileage'] = dataset['Mileage'].str.rstrip(' km')

"""Verifico di aver eliminato tutte le occorrenze di " km" in Mileage."""

# Specifica il suffisso da cercare (ad esempio, " km")
suffisso_da_cercare = " km"

# Conta il numero di occorrenze del suffisso nella colonna Mileage
numero_occasioni = (dataset['Mileage'].str.contains(suffisso_da_cercare)).sum()

# Stampa il risultato
print()
print("Rimozione della desinenza ' km' nella variabile Mileage")
print(f"Numero di occorrenze di '{suffisso_da_cercare}' nella colonna Mileage: {numero_occasioni}")

#converto il dato Milages da stringa a numero
dataset['Mileage'] = pd.to_numeric(dataset['Mileage'], errors='coerce')

dataset = dataset[(dataset['Price'] >= 4000) & (dataset['Price'] <= 700000)]


"""L'attributo dataset "Manufacturer" ha diversi valori unici i quali non rappresentano un informazione utile per effettuare una predizione quindi creo una nuova categorica Other nelle quali le accorpo."""

# Calcola il conteggio delle occorrenze di ciascun valore nella colonna 'Manufacturer'
manufacturer_counts = dataset['Manufacturer'].value_counts()

# Identifica i valori che si verificano meno di 5 volte
values_to_replace = manufacturer_counts[manufacturer_counts <= 10].index

# Sostituisci i valori con 'Other'
dataset['Manufacturer'] = dataset['Manufacturer'].replace(values_to_replace, 'Other')

dataset['Manufacturer'].value_counts()

"""Fare prima "One Hot Encoding" e il "Data Scaling"?
Dipende dalla situazione bisogna provare entrambi.
Provo prima a fare "Data Scaling" e poi "One Hot Encoding" quando avro bisogno di utilizzare un algoritmo che si basa solo su valori numerici.
Utilizzo Z-Score Normalization visto che per algoritmi come Regressione lineare risulta generalmente mogliore, visto che porta piu velocemente a convergenza.
"""

from sklearn.preprocessing import StandardScaler

# Seleziona solo le colonne numeriche su cui applicare lo Z-score
colonnes_numeriche = dataset.select_dtypes(include=['int64', 'float64']).columns

# Inizializza lo StandardScaler
scaler = StandardScaler()

# Applica lo Z-score alle colonne numeriche
dataset[colonnes_numeriche] = scaler.fit_transform(dataset[colonnes_numeriche])

"""Calcolo la correlazione di Pearson per determinare la correlazione delle variabili numeriche"""

from scipy.stats import pearsonr

# Seleziona solo le colonne numeriche
colonnes_numeriche = ['Mileage', 'Prod. year', 'Cylinders', 'Airbags']

# Calcola il coefficiente di correlazione di  Pearson solo per le coppie che contengono "Price"
for colonna in colonnes_numeriche:
    correlation_spearman, p_value_spearman = pearsonr(dataset['Price'], dataset[colonna])
    print(f"Coefficiente di correlazione di  Pearson tra Price e {colonna}: {correlation_spearman}\nP-value: {p_value_spearman}\n")

"""Ecco l'interpretazione dei risultati ottenuti:

Come criterio per determinare la correlazione tra la variabile Price che è nimerica e le variabili categoriche ho deciso di analizzare la varianza applicando la technica ANOVA.
"""

from scipy.stats import f_oneway

# Trova le categorie uniche di 'Manufacturer'
manufacturer_categories = dataset['Manufacturer'].unique()

# Crea una lista di serie contenenti i prezzi per ogni categoria
price_by_category = [dataset[dataset['Manufacturer'] == category]['Price'] for category in manufacturer_categories]

# Esegui l'ANOVA utilizzando le serie dei prezzi
f_statistic, p_value = f_oneway(*price_by_category)

# Stampa dei risultati
print()
print("Risultato di ANOVa per la variabile Manufacturer:")
print(f"F-statistic: {f_statistic}")
print(f"P-value: {p_value}")

"""P-value inferoiore a 0.05 cio significa che probabilmente la correlazione tra la categoria ed il prezzo e molto alta quindi questo parametro ha un alto valore predittivo."""

# Trova le categorie uniche di 'Model'
manufacturer_categories = dataset['Model'].unique()

# Crea una lista di serie contenenti i prezzi per ogni categoria
price_by_category = [dataset[dataset['Model'] == category]['Price'] for category in manufacturer_categories]

# Esegui l'ANOVA utilizzando le serie dei prezzi
f_statistic, p_value = f_oneway(*price_by_category)

# Stampa dei risultati
print()
print("Risultato di ANOVa per la variabile Model:")
print(f"F-statistic: {f_statistic}")
print(f"P-value: {p_value}")

"""Dato l'elevato numero di dati unici, potenza predittiva nulla(su 19000 record 17077 categorie diverse).

"""

# Trova le categorie uniche di 'Category'
manufacturer_categories = dataset['Category'].unique()

# Crea una lista di serie contenenti i prezzi per ogni categoria
price_by_category = [dataset[dataset['Category'] == category]['Price'] for category in manufacturer_categories]

# Esegui l'ANOVA utilizzando le serie dei prezzi
f_statistic, p_value = f_oneway(*price_by_category)

# Stampa dei risultati
print()
print("Risultato di ANOVa per la variabile Category:")
print(f"F-statistic: {f_statistic}")
print(f"P-value: {p_value}")

"""P-value inferoiore a 0.05 cio significa che probabilmente la correlazione tra la categoria ed il prezzo e molto alta quindi questo parametro ha un alto valore predittivo."""

# Trova le categorie uniche di 'Leather interior'
manufacturer_categories = dataset['Leather interior'].unique()

# Crea una lista di serie contenenti i prezzi per ogni categoria
price_by_category = [dataset[dataset['Leather interior'] == category]['Price'] for category in manufacturer_categories]

# Esegui l'ANOVA utilizzando le serie dei prezzi
f_statistic, p_value = f_oneway(*price_by_category)

# Stampa dei risultati
print()
print("Risultato di ANOVa per la variabile Leather interior:")
print(f"F-statistic: {f_statistic}")
print(f"P-value: {p_value}")

"""P-value inferoiore a 0.05 cio significa che probabilmente la correlazione tra la categoria ed il prezzo e molto alta quindi questo parametro ha un alto valore predittivo."""

# Trova le categorie uniche di 'Fuel type'
manufacturer_categories = dataset['Fuel type'].unique()

# Crea una lista di serie contenenti i prezzi per ogni categoria
price_by_category = [dataset[dataset['Fuel type'] == category]['Price'] for category in manufacturer_categories]

# Esegui l'ANOVA utilizzando le serie dei prezzi
f_statistic, p_value = f_oneway(*price_by_category)

# Stampa dei risultati
print()
print("Risultato di ANOVa per la variabile Fuel type:")
print(f"F-statistic: {f_statistic}")
print(f"P-value: {p_value}")

"""P-value inferoiore a 0.05 cio significa che probabilmente la correlazione tra la categoria ed il prezzo e molto alta quindi questo parametro ha un alto valore predittivo."""

# Trova le categorie uniche di 'Gear box type'
manufacturer_categories = dataset['Gear box type'].unique()

# Crea una lista di serie contenenti i prezzi per ogni categoria
price_by_category = [dataset[dataset['Gear box type'] == category]['Price'] for category in manufacturer_categories]

# Esegui l'ANOVA utilizzando le serie dei prezzi
f_statistic, p_value = f_oneway(*price_by_category)

# Stampa dei risultati
print()
print("Risultato di ANOVa per la variabile Gear box type:")
print(f"F-statistic: {f_statistic}")
print(f"P-value: {p_value}")

"""P-value inferoiore a 0.05 cio significa che probabilmente la correlazione tra la categoria ed il prezzo e molto alta quindi questo parametro ha un alto valore predittivo."""

# Trova le categorie uniche di 'Drive wheels'
manufacturer_categories = dataset['Drive wheels'].unique()

# Crea una lista di serie contenenti i prezzi per ogni categoria
price_by_category = [dataset[dataset['Drive wheels'] == category]['Price'] for category in manufacturer_categories]

# Esegui l'ANOVA utilizzando le serie dei prezzi
f_statistic, p_value = f_oneway(*price_by_category)

# Stampa dei risultati
print()
print("Risultato di ANOVa per la variabile Drive wheels:")
print(f"F-statistic: {f_statistic}")
print(f"P-value: {p_value}")

"""P-value inferoiore a 0.05 cio significa che probabilmente la correlazione tra la categoria ed il prezzo e molto alta quindi questo parametro ha un alto valore predittivo."""

# Trova le categorie uniche di 'Doors'
manufacturer_categories = dataset['Doors'].unique()

# Crea una lista di serie contenenti i prezzi per ogni categoria
price_by_category = [dataset[dataset['Doors'] == category]['Price'] for category in manufacturer_categories]

# Esegui l'ANOVA utilizzando le serie dei prezzi
f_statistic, p_value = f_oneway(*price_by_category)

# Stampa dei risultati
print()
print("Risultato di ANOVa per la variabile Doors:")
print(f"F-statistic: {f_statistic}")
print(f"P-value: {p_value}")

"""P-value inferoiore a 0.05 cio significa che probabilmente la correlazione tra la categoria ed il prezzo e molto alta quindi questo parametro ha un alto valore predittivo."""

# Trova le categorie uniche di 'Wheel'
manufacturer_categories = dataset['Wheel'].unique()

# Crea una lista di serie contenenti i prezzi per ogni categoria
price_by_category = [dataset[dataset['Wheel'] == category]['Price'] for category in manufacturer_categories]

# Esegui l'ANOVA utilizzando le serie dei prezzi
f_statistic, p_value = f_oneway(*price_by_category)

# Stampa dei risultati
print()
print("Risultato di ANOVa per la variabile Wheel:")
print(f"F-statistic: {f_statistic}")
print(f"P-value: {p_value}")

"""P-value inferoiore a 0.05 cio significa che probabilmente la correlazione tra la categoria ed il prezzo e molto alta quindi questo parametro ha un alto valore predittivo."""

# Trova le categorie uniche di 'Color'
manufacturer_categories = dataset['Color'].unique()

# Crea una lista di serie contenenti i prezzi per ogni categoria
price_by_category = [dataset[dataset['Color'] == category]['Price'] for category in manufacturer_categories]

# Esegui l'ANOVA utilizzando le serie dei prezzi
f_statistic, p_value = f_oneway(*price_by_category)

# Stampa dei risultati
print()
print("Risultato di ANOVa per la variabile Color:")
print(f"F-statistic: {f_statistic}")
print(f"P-value: {p_value}")

"""P-value inferoiore a 0.05 cio significa che probabilmente la correlazione tra la categoria ed il prezzo e molto alta quindi questo parametro ha un alto valore predittivo."""




"""Prima di poter applicare un algoritmo di Decision Three o di Regressione lineare bisogna trasformare le variabili categoriche in variabili numeriche."""

from sklearn.preprocessing import LabelEncoder

# Seleziona colonne categoriche
colonne_categoriche = dataset.select_dtypes(include=['object']).columns

# Applica Label Encoding a ciascuna colonna categorica
label_encoder = LabelEncoder()
for colonna in colonne_categoriche:
    dataset[colonna] = label_encoder.fit_transform(dataset[colonna])

# Stampa il DataFrame dopo Label Encoding
print("\nDataFrame dopo Label Encoding:")
print(dataset)




import numpy as np
from sklearn.model_selection import cross_validate
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import make_scorer, r2_score, mean_squared_error, mean_absolute_percentage_error

# Seleziona le feature e la variabile target
features = [colonna for colonna in dataset.columns if colonna != 'Price']
X = dataset[features]
y = dataset['Price']

# Definisci le metriche
metriche = {
    'R-squared': make_scorer(r2_score),
    'MAPE': make_scorer(mean_absolute_percentage_error),
    'MSE': make_scorer(mean_squared_error),
    'RMSE': make_scorer(lambda y_true, y_pred: np.sqrt(mean_squared_error(y_true, y_pred))),
}

# Modello di albero decisionale per la regressione
modello_albero_regressione = DecisionTreeRegressor()

# Esegui la K-Fold Cross-Validation con diverse metriche
risultati = cross_validate(modello_albero_regressione, X, y, cv=10, scoring=metriche)

# Stampa i risultati
print()
print("Modello ad albero decisionale metriche:")
for metrica, valori in risultati.items():
    print(f"{metrica} medio: {np.mean(valori)}")




from sklearn.linear_model import LinearRegression

# Modello di regressione lineare
modello_lineare_regressione = LinearRegression()


# Esegui la K-Fold Cross-Validation con diverse metriche
risultati = cross_validate(modello_lineare_regressione, X, y, cv=10, scoring=metriche)

# Stampa i risultati
print()
print("Modello di regressione lineare metriche:")
for metrica, valori in risultati.items():
    print(f"{metrica} medio: {np.mean(valori)}")

"""tutte le metriche sono mogliorate risulta generalmente mogliore.

**R-squared medio:**
Il R-squared medio è negativo, il che indica che il modello di regressione lineare non riesce a catturare la variazione nei dati di output. Potrebbe indicare che il modello non è adatto per il tipo di relazione tra le variabili indipendenti e dipendenti.

**Errore Assoluto Medio (MAE) medio:**
Il MAE medio è di circa 0.072, il che potrebbe essere considerato relativamente basso. Indica che, in media, le predizioni del modello si discostano di circa 0.051 unità dalla variabile target reale.

**Errore Quadrato Medio (MSE) medio: **
Il MSE medio è di circa 1.000, il che rappresenta la media degli errori quadrati. Tuttavia, questa metrica può essere influenzata da valori anomali.

**Radice dell'Errore Quadrato Medio (RMSE) medio:**
Il RMSE medio è di circa 0.408, che rappresenta la radice quadrata del MSE. Indica la deviazione standard degli errori del modello. Come il MAE, è una misura della precisione delle predizioni.

Il R-squared (coefficiente di determinazione) fornisce una misura della bontà di adattamento del modello ai dati. Il suo valore può variare da -∞ a 1, dove 1 indica un modello perfetto che spiega tutta la variazione nei dati. Tuttavia, è possibile ottenere valori negativi, il che indica che il modello è peggiore rispetto a un modello medio che prenderebbe semplicemente la media della variabile target.

Un R-squared negativo può verificarsi quando il modello lineare non è in grado di catturare la variazione nei dati, e l'output previsto è peggio di una semplice stima della media. In altre parole, il modello non fornisce alcun beneficio rispetto a una stima costante. Questo può accadere quando la relazione tra le variabili indipendenti e dipendenti non è approssimabile da una funzione lineare.

In sostanza, un R-squared medio negativo indica che il modello di regressione lineare attuale non è adatto per la previsione della variabile target nel tuo dataset. Potrebbe essere necessario esplorare modelli più complessi o considerare altre trasformazioni delle variabili per migliorare le prestazioni del modello.
"""